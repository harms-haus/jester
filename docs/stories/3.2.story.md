# Story 3.2: LightRAG Query Integration

## Story Information
- **Epic**: 3 - LightRAG Integration
- **Story Number**: 3.2
- **Status**: Ready for Review
- **Created**: 2025-01-27
- **Last Modified**: 2025-01-27

## Story Statement

As a **parent creating bedtime stories**,
I want **the system to query LightRAG for relevant entities**,
so that **my stories can include discovered characters, locations, and items**.

## Acceptance Criteria

1. **Context generation** queries LightRAG for relevant entities during `/muse` command
2. **Entity suggestions** are provided based on story context and requirements
3. **Entity integration** incorporates selected entities into local story context
4. **Error handling** provides graceful fallback when LightRAG service is unavailable

## Tasks / Subtasks

- [x] Task 1: Implement LightRAG Context Generation (AC: 1)
  - [x] 1.1. Integrate LightRAG queries into `/muse` command workflow
  - [x] 1.2. Create context-aware query generation based on story requirements
  - [x] 1.3. Add error handling for LightRAG service unavailability

- [x] Task 2: Implement Entity Suggestion System (AC: 2)
  - [x] 2.1. Create entity suggestion algorithm using LightRAG query results
  - [x] 2.2. Implement suggestion ranking based on relevance scores

- [x] Task 3: Implement Entity Integration (AC: 3, 4)
  - [x] 3.1. Create entity integration into story context files
  - [x] 3.2. Add error handling for LightRAG service unavailability

## Dev Notes

### Previous Story Insights
From Story 3.1 (Entity Relationship Discovery), the system has established LightRAG integration capabilities for relationship discovery. This story builds upon that foundation by integrating LightRAG queries directly into the `/muse` command workflow for entity discovery during story creation.

### LightRAG Integration Requirements
This story focuses on basic LightRAG query integration for entity discovery during story creation. The implementation should follow the existing prompt-based agent architecture pattern.

### Data Models
[Source: architecture/data-models.md#Core Data Structures]

**Key Data Structures:**
- `StoryContext` with entities containing EntityReference arrays for characters, locations, and items
- `Entity` interface with id, name, type, description, properties, relationships, last_used, usage_count
- Entity types: 'character' | 'location' | 'item'

**Context File Structure:**
- YAML format for context files in `contexts/` directory
- Entity references with metadata and usage tracking
- Story requirements and target audience information

### API Specifications
[Source: architecture/api-specification.md#LightRAG OpenAPI Integration]

**Key LightRAG Endpoints:**
- `POST /query` - Natural language queries with reranking support
- `POST /query/data` - Structured data queries for knowledge graph entities and relationships
- `GET /graph/label/list` - Retrieve all node labels (IDs) in the datastore
- `GET /graphs` - Get graph node data

**Request/Response Format:**
- QueryRequest: { query: string, documents?: Array<{content: string, id: string}>, enable_rerank?: boolean }
- QueryResponse: { reranked_documents: Array<{content: string, id: string, score: number}> }
- DataQueryResponse: Contains entities, relationships, and chunks arrays with detailed metadata

**LightRAGClient Interface:**
- query(query: string, enableRerank?: boolean): Promise<QueryResponse>
- queryData(query: string, format?: string, includeVectors?: boolean): Promise<DataQueryResponse>
- getGraphLabels(): Promise<GraphLabelListResponse>
- getGraphNodes(): Promise<GraphNodeDataResponse>

### Component Specifications
[Source: architecture/components.md#Core Components]

**Agent System Integration:**
- `/muse` (Story Context Agent): Prompt rules for context gathering and entity discovery (Analyst role)
- External LLM follows Muse prompt rules to query LightRAG for entities
- LLM generates context file and saves to `contexts/` per prompt instructions

**File System Operations:**
- Entity file management (characters/, locations/, items/) via LLM operations
- Story file management (stories/, outlines/, contexts/) via LLM operations
- Wiki-style link parsing and validation via LLM operations

**Data Flow:**
1. User initiates `/muse` command
2. External LLM follows Muse prompt rules to query LightRAG for entities
3. LLM generates context file and saves to `contexts/` per prompt instructions
4. User edits context file
5. User runs `/write outline` and `/write story` commands

### File Locations
[Source: architecture/data-models.md#File System Structure]

**Project Structure:**
- Context files: `contexts/` directory
- Entity files: `entities/characters/`, `entities/locations/`, `entities/items/`
- LightRAG client: `src/clients/lightragClient.ts`
- Services: `src/services/lightragService.ts`
- Agent prompt rules: `.jester/agents/` (Muse agent)

### Technical Constraints
[Source: architecture/tech-stack.md#External Services]

**Dependencies:**
- LightRAG: Knowledge graph service for entity relationships
- MCP Client: Python client for LightRAG OpenAPI integration
- External LLM: Any LLM service capable of following prompt rules and performing file operations

**Performance Considerations:**
- Query caching to minimize LightRAG API calls
- Offline mode when LightRAG service unavailable
- Reranking enabled by default for better relevance
- Streaming support for real-time query results

**Architectural Patterns:**
- Agent-Based Architecture: Specialized agents with specific responsibilities
- File-Based Pipeline: Agents communicate through structured files
- Local-First Storage: All user data stored locally with optional cloud sync
- Knowledge Graph Integration: External knowledge graph for entity relationships

### Testing Requirements
Following general coding standards:
- Use try-catch blocks for async operations
- Provide meaningful error messages
- Log errors with context information
- Graceful degradation for non-critical failures

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|---------|
| 2025-01-27 | 1.0 | Initial story creation | Scrum Master |

## Dev Agent Record

### Agent Model Used
Claude Sonnet 4 (via Cursor)

### Debug Log References
- No debug log entries required for this prompt-based implementation

### Completion Notes List
- Successfully integrated LightRAG MCP client queries into `/muse` command workflow
- Created context-aware query generation system with age-appropriate filtering
- Implemented comprehensive entity suggestion algorithm with relevance scoring
- Added robust error handling for LightRAG service unavailability
- Updated context template to support LightRAG entity metadata
- Created new prompt files for query generation, suggestion algorithm, and entity integration
- All tasks completed successfully with full functionality

### File List
**Modified Files:**
- `.jester/agents/muse.md` - Updated with LightRAG integration and new commands
- `.jester/prompts/context-generation.md` - Enhanced with LightRAG query instructions
- `.jester/templates/context.yaml` - Updated to support LightRAG entity metadata

**New Files Created:**
- `.jester/prompts/lightrag-query-generation.md` - Context-aware query generation prompts
- `.jester/prompts/entity-suggestion-algorithm.md` - Entity suggestion and ranking algorithm
- `.jester/prompts/entity-integration.md` - Entity integration into story context prompts

## QA Results

*Results from QA Agent review will be populated here*

